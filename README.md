# ğŸ™ï¸ Perfect Voice Assistant

A state-of-the-art real-time speech-to-speech AI system with advanced WebRTC implementation, Voice Activity Detection (VAD), and enhanced audio processing.

## âœ¨ Features

### ğŸš€ **Perfect Implementation**
- **WebRTC-Ready Architecture** - Built for real-time communication
- **AudioWorklet Processing** - Modern, low-latency audio handling
- **Voice Activity Detection** - Intelligent speech detection
- **Enhanced Audio Processing** - Noise reduction, echo cancellation
- **Automatic Reconnection** - Robust connection management
- **Performance Monitoring** - Real-time metrics and analytics

### ğŸ¯ **Core Capabilities**
- **Speech-to-Text (STT)** - Kyutai STT 1B model with fallback
- **Language Model (LLM)** - Moshi conversational AI with context
- **Text-to-Speech (TTS)** - Enhanced voice synthesis
- **Real-time Processing** - Sub-second response times
- **Multi-platform Support** - Windows, macOS, Linux

### ğŸ”§ **Technical Excellence**
- **Modern Web APIs** - AudioWorklet, WebRTC, WebSockets
- **Asynchronous Pipeline** - Non-blocking audio processing
- **Circular Audio Buffering** - Efficient memory management
- **Graceful Degradation** - Fallback systems for reliability
- **Progressive Web App** - Offline capabilities with service worker

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8 or higher
- Node.js (for development)
- Git

### Automated Setup
```bash
# Clone the repository
git clone <your-repo-url>
cd perfect-voice-assistant

# Run the automated setup
python setup.py
```

### Manual Setup
```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# Unix/Linux/macOS:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Create directories
mkdir -p models/{stt,tts,llm} logs cache

# Download models (optional - fallbacks available)
python download_models.py

# Start the application
python app.py
```

### Start the Application
```bash
# Using startup scripts
./start.sh          # Unix/Linux/macOS
start.bat           # Windows

# Or directly
python app.py
```

Visit `http://localhost:8000` in your browser.

## ğŸ® Usage

### Basic Operation
1. **Connect** - The system automatically connects to the server
2. **Start Recording** - Click "ğŸ¤ Start Talking" or press `Ctrl+Space`
3. **Speak** - Talk naturally; VAD will detect your speech
4. **Get Response** - Receive AI-generated text and audio responses
5. **Stop Recording** - Click "â¹ï¸ Stop Recording" or press `Ctrl+Space` again

### Advanced Features
- **Voice Activity Detection** - Automatically processes speech segments
- **Real-time Audio Level** - Visual feedback of microphone input
- **Performance Metrics** - Monitor processing times and system health
- **Auto-reconnection** - Seamless recovery from connection issues
- **Keyboard Shortcuts** - `Ctrl+Space` to toggle recording

## ğŸ—ï¸ Architecture

### System Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚   Backend        â”‚    â”‚   AI Models     â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â€¢ AudioWorklet  â”‚â—„â”€â”€â–ºâ”‚ â€¢ FastAPI        â”‚â—„â”€â”€â–ºâ”‚ â€¢ Kyutai STT    â”‚
â”‚ â€¢ WebRTC Ready  â”‚    â”‚ â€¢ WebSockets     â”‚    â”‚ â€¢ Moshi LLM     â”‚
â”‚ â€¢ VAD           â”‚    â”‚ â€¢ Async Pipeline â”‚    â”‚ â€¢ Enhanced TTS  â”‚
â”‚ â€¢ Auto-reconnectâ”‚    â”‚ â€¢ Performance    â”‚    â”‚ â€¢ Fallbacks     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Audio Processing Pipeline

```
Microphone â†’ AudioWorklet â†’ VAD â†’ Buffer â†’ STT â†’ LLM â†’ TTS â†’ Speaker
     â†“              â†“         â†“       â†“      â†“     â†“     â†“
  16kHz Mono   Noise Reduce  Smart   Async  AI    AI   24kHz
  Echo Cancel  Level Detect  Chunk   Queue  Text  Voice Audio
```

### Key Technologies
- **Frontend**: Vanilla JavaScript, AudioWorklet, WebRTC APIs
- **Backend**: FastAPI, WebSockets, AsyncIO
- **AI Models**: Kyutai STT/TTS, Moshi LLM
- **Audio**: LibROSA, SciPy, NumPy
- **Performance**: Real-time metrics, connection management

## ğŸ”§ Configuration

### Environment Variables
```bash
# Optional configuration
export DEVICE=cuda              # Force GPU usage
export LOG_LEVEL=INFO          # Logging level
export MAX_CONNECTIONS=100     # WebSocket limit
export MODEL_CACHE_DIR=./models # Model storage
```

### Audio Settings
The system automatically configures optimal audio settings:
- **Sample Rate**: 16kHz (input), 24kHz (output)
- **Channels**: Mono
- **Buffer Size**: 1024 samples
- **Latency**: ~10ms
- **Processing**: Echo cancellation, noise suppression

## ğŸ“Š Performance

### Benchmarks
- **End-to-End Latency**: < 2 seconds
- **STT Processing**: < 500ms
- **LLM Generation**: < 800ms  
- **TTS Synthesis**: < 700ms
- **Audio Latency**: < 50ms

### System Requirements
- **Minimum**: 4GB RAM, 2-core CPU
- **Recommended**: 8GB RAM, 4-core CPU, GPU
- **Storage**: 5GB for models, 1GB for cache
- **Network**: Stable internet for model downloads

## ğŸ› ï¸ Development

### Project Structure
```
perfect-voice-assistant/
â”œâ”€â”€ app.py                 # Main application
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ setup.py              # Automated setup script
â”œâ”€â”€ download_models.py    # Model download utility
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ script.js         # Frontend JavaScript
â”‚   â”œâ”€â”€ style.css         # Enhanced styling
â”‚   â”œâ”€â”€ audio-worklet.js  # Audio processing
â”‚   â””â”€â”€ sw.js            # Service worker
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html       # Main interface
â”œâ”€â”€ tts_model_def/       # TTS model definitions
â”œâ”€â”€ models/              # AI model storage
â””â”€â”€ logs/               # Application logs
```

### API Endpoints
- `GET /` - Main interface
- `GET /status` - System status and metrics
- `GET /health` - Health check
- `WebSocket /ws` - Real-time audio communication

### WebSocket Protocol
```json
// Client to Server
{
  "type": "audio",
  "audio": [0.1, -0.2, 0.3, ...]  // Float32Array
}

// Server to Client
{
  "transcription": "Hello world",
  "response_text": "Hi there!",
  "response_audio": [0.1, -0.2, ...],
  "processing_time": {
    "stt": 0.45,
    "llm": 0.78,
    "tts": 0.62,
    "total": 1.85
  }
}
```

## ğŸ” Troubleshooting

### Common Issues

**Microphone Access Denied**
- Ensure HTTPS or localhost
- Check browser permissions
- Restart browser if needed

**Models Not Loading**
- Run `python download_models.py`
- Check internet connection
- Verify disk space (5GB needed)

**High Latency**
- Check system resources
- Ensure GPU availability
- Reduce concurrent connections

**Connection Issues**
- Verify firewall settings
- Check WebSocket support
- Try different browser

### Debug Mode
```bash
# Enable debug logging
export LOG_LEVEL=DEBUG
python app.py
```

### Performance Monitoring
Access real-time metrics at `/status` endpoint or in the web interface.

## ğŸ¤ Contributing

We welcome contributions! Please see our contributing guidelines:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

### Development Setup
```bash
# Install development dependencies
pip install -r requirements-dev.txt

# Run tests
python -m pytest tests/

# Format code
black app.py
isort app.py
```

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- **Kyutai** - For the excellent STT and TTS models
- **Moshi** - For the conversational AI capabilities
- **FastAPI** - For the robust web framework
- **Web Audio API** - For modern audio processing

## ğŸ“ Support

- **Issues**: GitHub Issues
- **Discussions**: GitHub Discussions
- **Documentation**: This README and inline comments

---

**ğŸ™ï¸ Perfect Voice Assistant** - Where speech meets intelligence, perfectly implemented.